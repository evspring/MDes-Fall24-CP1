<!DOCTYPE html>
<html lang="en">
<head>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.11.1/p5.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.11.1/addons/p5.sound.min.js"></script>
    <script src="https://unpkg.com/ml5@1/dist/ml5.min.js"></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Word Ordering Code</title>
</head>
<body>
    <h1>Word Ordering Code (available at bottom of page)</h1>


    </div>

    <script>
        let video; let handPose; let hands = [];
        let font; let size = 35;
        let words = []; let num = 5;
        
        function preload() {
          font = loadFont("Outfit-VariableFont_wght.ttf");
          handPose = ml5.handPose({flipped: true});
        }
        
        function setup() {
          createCanvas(640, 480);
          video = createCapture(VIDEO,{flipped:true},function(){});
          video.hide();
          handPose.detectStart(video, gotHands);
          
          //creating word boxes
          rectMode(CENTER);
          for (let i=0; i<num; i++) {
            words[i] = new Word();
          }
        }
        
        function draw() {
          background(220);
          
          // detect thumb and index keypoints
          image(video, 0, 0, width, height);
          if (hands.length > 0) {
            let index = hands[0].keypoints[8];
            let thumb = hands[0].keypoints[4];
            
            noFill();
            stroke(0, 255, 0);
            text("index", index.x, index.y);
            text("thumb", thumb.x, thumb.y);
          
            for (let i=0; i<num; i++) {
              words[i].touch(thumb.x, thumb.y, index.x, index.y);
            }
          }
          
          for (let i=0; i<num; i++) {
            words[i].display();
          }
        }
        
        function gotHands(results) {
          hands = results;
        }
    
        let textWords = ["Interaction", "Design", "Prototype", "ArtCenter"];
    
        class Word {
      constructor() {
        this.t = random(textWords);
        this.x = random(width);
        this.y = random(height);
        this.angle = random(TWO_PI);
        this.c = color(255);
        
        this.bbox = font.textBounds(this.t, this.x, this.y, size);
        this.pos = createVector(this.bbox.x, this.bbox.y);
        this.w = this.bbox.w;
        this.h = this.bbox.h;
        
        this.fingerx = 0;
        this.fingery = 0;
      }
      
      display() {
       //moving boxes to fit in frame and rotate randomly
        push();
        translate(this.pos.x, this.pos.y);
        rotate(this.angle);
        fill(this.c);
        rect(0, 0, this.w, this.h);
    
      //creating word box style
        fill(0);
        noStroke();
        textFont(font);
        textSize(size/2);
        textAlign(CENTER, CENTER);
        text(this.t, 0, 0);
        pop();
        
        fill(255, 0, 0);
        ellipse(this.fingerx, this.fingery, 10, 10);
      }
      //allowing for "touch" controls with grabbing and dropping
      touch(thumbx, thumby, indexx, indexy) {
        let distBetweenFingers = dist(thumbx, thumby, indexx, indexy);
        this.fingerx = abs(thumbx - indexx) + min(thumbx, indexx);
        this.fingery = abs(thumby - indexy) + min(thumby, indexy);
        
        let distFromFingers = dist(this.pos.x, this.pos.y, this.fingerx, this.fingery);
        
        if (distBetweenFingers < 40 && distFromFingers < this.w/2) {
          this.c = color(255, 0, 0);
          this.pos.x = this.fingerx;
          this.pos.y = this.fingery;
        } else {
          this.c = color(255);
        }
      }
        }
    </script>

    <div>

        <p1>My proposal for the project was to create a code that can detect faces/people in real time and possibly even make inferences on things like emotional state. This is something that I commonly saw utilized in the psychology field for research purpose during my undergraduate studies and I think it would be interesting to try and recreate this. This would be run through my web camera and detect people in my room.
   
           </p1>
   
       </div>
       <p>

       </p>
       <div>
   
           <p2>I’d also love if it could do facial tracking and be able to tell where faces are and be able to display that. I feel like I essentially want to create that CCTV footage program that detects faces and people.
           </p2>
           <p>

           </p>
        <p3>The first thing I did was dive into the ml5.js reference tab and look into what kinds of facial recognition features existed in the ml5 library. I found something called BodyPose which is a “The ml5.js BodyPose is a pretrained full-body pose estimation model that can estimate poses and track key body parts in real-time.” This proved to be very helpful for starting out and understanding what I was working with in ml5. However I really wanted something that would be more specific to the face and not the pose, so I needed to continue looking further. 
   
           </p3>
   
       </div>
       <p>

       </p>
       <div>
           <img src = "BodyPose.png"><img>
           <p>

           </p>
   
           <p4> Now that I know roughly what I want to do, I needed to find a library to further support what I was doing. I browsed around a bit, looking into both YouTube tutorials and the ml5 library and eventually found FaceMesh, which was exactly what I was looking for. 
           </p4>
   
       </div>
         <p>

        </p>
       <div>
           <img src = "FaceMesh.png"><img>

           <p>

           </p>
   
           <p5> By following the instructions and example code provided by ML5, I was able to incorporate facial tracking into my p5 file. It now looked something like this:
           </p5>
   
       </div>
       <p>

       </p>
   
       <div>
           <img src = "FacialTracking.png"><img>
            <p>

            </p>
           <p6> My code looked like this:</p6>
   
       </div>
       <p>

       </p>
       <div>
        <img src = "FaceCode.png"><img>
   
        <p>

        </p>
        <p7> Now that I had my facial tracking setup I wanted to be able to add more onto it. In particular, I wanted to be able to find out how to add expression reading to it, including things like opening and closing your mouth. My goal is to be able to code something like opening your mouth triggering a background scene change.
        </p7>
        <p>

        </p>
    <div>
        <h2>At this point, some things changed.</h2>
        <p3>Originally, I was planning on using face mesh as a trigger, but some key concerns were pointed out with my original intentions and I decided to move away from that project. I considered trying something like making a code where opening and closing your mouth create a trigger. That would’ve been interesting, however with some more research on ml5js, as well as looking up YouTube videos and discussions about the different things I could do, I decided to go along a different route.
        </p3>
        <p4>Instead I chose to go with using handPose in ml5js, my goal is going to be to create an interactive program where you can use your hands on the camera in order move stuff around on the screen.
        </p4>
    
        <div>
            <p>
                
            </p>
    
        </div>

    <div>
        <p5>To start I imported the handPose code into p5js
        </p5>

    </div>

    <div>
        <p>
            
        </p>

    </div>

    <img src = "handpose1.png"><img>

    <div>
        <p>
            
        </p>

    </div>

    <p6>Once I played around with handPose for a bit I started working on my code. To start I created my camera, I did my best to make for a good interactive experience by “flipping” it.</p6>

    <div>
        <p>
            
        </p>

    </div>

    <img src = "cameracode.png"><img>

    <div>
        <p>
            
        </p>

    </div>

    <p>For much of this process I was following some video tutorials on how to set up this kind of interaction correctly. Turns out, you can alter which specific “key points” to highlight and in my case, do things. In my case I want to track my index finger and my thumb so I can later try and grab things with those two points. I started by setting up handPose to track a few of the specific key points with the HandPose 
        </p>
    
    <div>
        <p>

        </p>
    </div>
    <div>
        <img src="keypoints.png"><img>
    </div>
    <div>
        <p>

        </p>
    </div>

    <p>My next step was setting up the text so that it could be placed on the screen and then manipulated through handPose and the keypoints. I started out by making them appear randomly on the screen.</p>
    <div>
        <p>

        </p>
    </div>
    <img src="textsetup.png"><img>
    <div>
        <p>

        </p>
    </div>
    <p>I also learned how to implement fonts into p5 (thank you YouTube!) so I chose a font for the text and applied it, I used a font called Outfit for the words</p>
    <p>

    </p>
    <p>At this point my output was looking something like the image below, but I had a few problems... for one, the words all started in the top left which I didn't love, and second, the actual grabbing on the words wasn't working yet either, so I needed to set that up.</p>
    
    <div>
        <p>

        </p>
    </div>
    <img src="testone.png"><img>
    <div>
        <p>

        </p>
    </div>
    <p>Thankfully this was an easy fix, I had mispelled some things which was why the code wasn't working, and simply added a tranlate and rotation variable so the words would be randomly dispersed and rotated throughout the screen, rather then just being in the top left corner. Now my code worked and looked like this.</p>
    <div>
        <p>

        </p>
    </div>
    <img src = "working.png"><img>

    <div>
        <p>

        </p>
    </div>
    <div>
        <p>

        </p>
    </div>
    <p>This project absolutely would not have been feasible for me without some wonderful YouTube tutorials. In that regard I'd love to give credit to the Channels "The Coding Train", "Patt Vira", "Kazuki Umeda", and many others. The tips and showcases of how to use the ml5 library with p5 were invaluable. </p>
    

</body>
</html>